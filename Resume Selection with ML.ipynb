{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4a2770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 1: IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d357fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\karan\\anaconda3\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\karan\\anaconda3\\lib\\site-packages (1.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\karan\\anaconda3\\lib\\site-packages (3.4.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from matplotlib) (1.20.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: six in c:\\users\\karan\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\karan\\anaconda3\\lib\\site-packages (0.11.2)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from seaborn) (1.7.1)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from seaborn) (1.3.4)\n",
      "Requirement already satisfied: matplotlib>=2.2 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from seaborn) (3.4.3)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from seaborn) (1.20.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (8.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\karan\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: pip in c:\\users\\karan\\anaconda3\\lib\\site-packages (21.2.4)\n",
      "Collecting pip\n",
      "  Downloading pip-22.0.3-py3-none-any.whl (2.1 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.2.4\n",
      "    Uninstalling pip-21.2.4:\n",
      "      Successfully uninstalled pip-21.2.4\n",
      "Successfully installed pip-22.0.3\n",
      "Requirement already satisfied: nltk in c:\\users\\karan\\anaconda3\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\karan\\anaconda3\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\karan\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\karan\\anaconda3\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\karan\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.1.2-cp39-cp39-win_amd64.whl (24.0 MB)\n",
      "     ---------------------------------------- 24.0/24.0 MB 7.4 MB/s eta 0:00:00\n",
      "Collecting Cython==0.29.23\n",
      "  Downloading Cython-0.29.23-cp39-cp39-win_amd64.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 5.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from gensim) (1.20.3)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 58.6/58.6 KB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from gensim) (1.7.1)\n",
      "Installing collected packages: smart-open, Cython, gensim\n",
      "  Attempting uninstall: Cython\n",
      "    Found existing installation: Cython 0.29.24\n",
      "    Uninstalling Cython-0.29.24:\n",
      "      Successfully uninstalled Cython-0.29.24\n",
      "Successfully installed Cython-0.29.23 gensim-4.1.2 smart-open-5.2.1\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\karan\\anaconda3\\lib\\site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.20.3)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1309 sha256=802ff170764fb9bd96f5a772580aac93cac32a95cce727fde0d09dea1ebb9f53\n",
      "  Stored in directory: c:\\users\\karan\\appdata\\local\\pip\\cache\\wheels\\e4\\7b\\98\\b6466d71b8d738a0c547008b9eb39bf8676d1ff6ca4b22af1c\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn\n",
      "Successfully installed sklearn-0.0\n",
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.8.1.tar.gz (220 kB)\n",
      "     -------------------------------------- 220.7/220.7 KB 2.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from wordcloud) (1.20.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\karan\\anaconda3\\lib\\site-packages (from wordcloud) (8.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\karan\\anaconda3\\lib\\site-packages (from wordcloud) (3.4.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\karan\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\karan\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.16.0)\n",
      "Building wheels for collected packages: wordcloud\n",
      "  Building wheel for wordcloud (setup.py): started\n",
      "  Building wheel for wordcloud (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for wordcloud\n",
      "Failed to build wordcloud\n",
      "Installing collected packages: wordcloud\n",
      "  Running setup.py install for wordcloud: started\n",
      "  Running setup.py install for wordcloud: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [20 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.9\n",
      "  creating build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\color_from_image.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\tokenization.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\wordcloud.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\wordcloud_cli.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\_version.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\__init__.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\__main__.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\stopwords -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\DroidSansMono.ttf -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  UPDATING build\\lib.win-amd64-3.9\\wordcloud/_version.py\n",
      "  set build\\lib.win-amd64-3.9\\wordcloud/_version.py to '1.8.1'\n",
      "  running build_ext\n",
      "  building 'wordcloud.query_integral_image' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for wordcloud\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Running setup.py install for wordcloud did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [20 lines of output]\n",
      "  running install\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.9\n",
      "  creating build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\color_from_image.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\tokenization.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\wordcloud.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\wordcloud_cli.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\_version.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\__init__.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\__main__.py -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\stopwords -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  copying wordcloud\\DroidSansMono.ttf -> build\\lib.win-amd64-3.9\\wordcloud\n",
      "  UPDATING build\\lib.win-amd64-3.9\\wordcloud/_version.py\n",
      "  set build\\lib.win-amd64-3.9\\wordcloud/_version.py to '1.8.1'\n",
      "  running build_ext\n",
      "  building 'wordcloud.query_integral_image' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "Encountered error while trying to install package.\n",
      "\n",
      "wordcloud\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11052/2138031299.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "# INSTALLING NLTK, GENSIM AND WORDCLOUD\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install --upgrade pip\n",
    "!pip install nltk\n",
    "!pip install gensim\n",
    "!pip install sklearn\n",
    "!pip install wordcloud\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b8d860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 2: LOADING THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55458964",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_df = pd.read_csv('data/resume_data.csv', encoding = 'latin-1')\n",
    "resume_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef3b252",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_df = resume_df[['resume_text', 'class']]\n",
    "resume_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83761621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 3: PERFORMING EXPLORATORY DATA ANALYSIS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d7b806",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc420834",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2817bc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE WE OBSERVE, WE HAVE NO NULL POINTS IN OUR DATASET\n",
    "resume_df['class'] = resume_df['class'].apply(lambda x:1 if x == 'flagged' else 0)\n",
    "resume_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da031b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 4: PERFORMING DATA CLEANING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae77557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREMOVING UNNECESSARY WORDS FROM DATASET\n",
    "\n",
    "resume_df['resume_text'] = resume_df['resume_text'].apply(lambda x: x .replace('\\r', ''))\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "stop_words.extend(['from', 'subject', 'edu', 're', 'use', 'email', 'com'])\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 2 and token not in stop_words:\n",
    "            result.append(token)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56769002",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e1ba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_df['cleaned'] = resume_df['resume_text'].apply(preprocess)\n",
    "\n",
    "resume_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff55d3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_df['cleaned'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df79bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 5: VISUALIZING CLEANED DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb464eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING COUNTS OF SAMPLE LABELLED AS 1 AND 0\n",
    "sns.countplot(resume_df['class'], label = 'Count Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a12380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING THE WORDCLOUD:\n",
    "\n",
    "# 1) FOR CLASS 1:\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize = (20, 20))\n",
    "\n",
    "wc = WordCloud(max_words = 2000, width = 1600, height = 800, stopwords = stop_words).generate(str(resume_df[resume_df['class']==1].cleaned))\n",
    "\n",
    "plt.imshow(wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d64bf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) FOR CLASS 0:\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize = (20, 20))\n",
    "\n",
    "wc = WordCloud(max_words = 2000, width = 1600, height = 800, stopwords = stop_words).generate(str(resume_df[resume_df['class']==0].cleaned))\n",
    "\n",
    "plt.imshow(wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da3673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 6: PREPARING THE DATA BY APPLYING COUNT VECTORIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed802ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERTING SENTENCES INTO TOKENIZED FORMS AND THEN CONVERTING TO NUMERICAL VALUES IN ORDER FOR THE MODEL TO TRAIN:\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "countvectorizer = vectorizer.fit_transform(resume_df['cleaned'])\n",
    "\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0a096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESSED DATA:\n",
    "print(countvectorizer.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7185a9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 7: TRAINING A NAIVE BAYES CLASSIFER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9399be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = countvectorizer\n",
    "y = resume_df['class']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "Bayes_clf = MultinomialNB(alpha = 3)\n",
    "Bayes_clf.fit(X_train, y_train)  ## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61ed35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 8: ASSESING THE TRAINED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e542d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# PLOTTING CONFUSION MATRIX:\n",
    "\n",
    "# 1) FOR TRAINING DATA\n",
    "\n",
    "y_pred_train = Bayes_clf.predict(X_train)\n",
    "\n",
    "cm = confusion_matrix(y_train, y_pred_train)\n",
    "\n",
    "sns.heatmap(cm, annot=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f2d89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# WE CAN SEE OUR MODEL PERFORMED REALLY WELL ON TRAINING DATA: IT CLASSFIED ALL OF THE POINTS CORRECTLY\n",
    "\n",
    "# 2) FOR TEST DATA:\n",
    "\n",
    "y_pred_test = Bayes_clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "sns.heatmap(cm, annot=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd567c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e1daa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "print(\"Accuracy of model on Train Dataset = {}\".format(accuracy_score(y_train, y_pred_train)))\n",
    "print(\"Accuracy of model on Test Dataset = {}\".format(accuracy_score(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab78d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of model is = {}\".format(accuracy_score(y_test, y_pred_test)))\n",
    "print(\"F1 of model is = {}\".format(f1_score(y_test, y_pred_test)))\n",
    "print(\"Precision of model is = {}\".format(precision_score(y_test, y_pred_test)))\n",
    "print(\"Recall of model is = {}\".format(recall_score(y_test, y_pred_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
